# Constraint Satisfaction Problem 
**Real Life examples:** Scheduling routine, assignment problems, transportation scheduling, circuit layout, hardware configuration, fault diagnosis etc

States are partial assignments
Goal test is defined by constraints 
Speed-ups: Ordering, Filtering, Structure

**MRV (Minimum Remaining Values)→** Selecting variable This heuristic involves selecting the variable with the fewest legal values left in its domain to assign next.

**LCV (Least Constraining Value)→** value assigning order

**Filtering ->** Keeping track of domains for unassigned variables and cross-off bad options 

**Forward Checking ->** Cross-off values that violate a constraint when added to the existing assignment 

**What to do?**
Choose the city with the minimum remaining value (MRV) Pick the color/city that eliminates the fewest options from other city’s domain (LCV) Propagate constraints to make auto/default assignments based on current state If we fail in any step, backtrack and select a different value/city.

### Solving a Constraint Satisfaction Problem (CSP) with an Example

Let's consider a classic example of CSP: **Map Coloring**. The goal is to color a map using a limited number of colors such that no adjacent regions (e.g., countries or states) share the same color.

#### **Problem Setup**
- **Regions**: A, B, C, D
- **Colors**: Red, Green, Blue
- **Constraints**: No two adjacent regions can have the same color.

#### **Step 1: States are Partial Assignments**
- We start with an empty map where no regions are colored. As we progress, we'll assign colors to regions while respecting the constraints.

#### **Step 2: Applying MRV (Minimum Remaining Values) Heuristic**
- **Goal**: Select the region with the fewest possible legal colors remaining.
- Initially, each region has 3 possible colors (Red, Green, Blue).

Let's assume regions A and B are adjacent, B and C are adjacent, and C and D are adjacent. We start by selecting region A (any region can be selected initially).

#### **Step 3: Applying LCV (Least Constraining Value) Heuristic**
- **Goal**: Choose the color that leaves the most options open for the remaining regions.
- Suppose we choose **Red** for region A. Now, region B can be either Green or Blue (but not Red), and the other regions still have all three colors available.

#### **Step 4: Filtering & Forward Checking**
- **Filtering**: Track the possible colors for each uncolored region.
- **Forward Checking**: After assigning Red to A, we update the possibilities for B. Since B is adjacent to A, we eliminate Red from B's domain. Now, B can only be Green or Blue.

#### **Step 5: Propagate Constraints**
- This involves updating the remaining regions based on current assignments. For example, if region B is assigned Green, forward checking will ensure that any neighboring region (like C) cannot have Green as an option.

#### **Step 6: Backtracking if Necessary**
- If a region is reached where no legal color can be assigned (all colors violate constraints), we backtrack to the previous region and try a different color.

#### **Example Execution**
1. **A = Red** (MRV & LCV applied)
   - B can now be either Green or Blue.

2. **B = Green** (LCV: Green might be better than Blue for B because it might leave more flexibility for other regions)
   - C can now be either Red or Blue.

3. **C = Red** 
   - D can now be either Green or Blue.

4. **D = Blue** (This is the only option left for D)

At this point, all regions have been assigned a color, and no adjacent regions share the same color. The solution is:

- **A = Red**
- **B = Green**
- **C = Red**
- **D = Blue**

This satisfies all constraints, so the problem is solved.

# ARC Consistency
- Node consistency = A single node follows its own unary constraints such as “City A will be blue” 
- Arc consistency = If a relation exists between A and B, and there is a relation between them, then that constraint satisfaction is called Arc consistency. 
- “City A and B will not be of same color” Filtering is not important for applying ARC consistency. We use AC3 algorithm
![[Pasted image 20240821223526.png]]
![[Pasted image 20240821223546.png]]
![[Pasted image 20240821225520.png]]
![[Pasted image 20240821225551.png]]

# K-Consistency 
1. **1-Consistency (Node Consistency):** This is the most basic form of consistency, ensuring that every value in a single variable's domain satisfies that variable's unary constraints. Unary constraints are the rules that apply to a single variable. 
   
2. **2-Consistency (Arc Consistency):** This level of consistency concerns pairs of variables. A CSP is 2-consistent if, *for every value of one variable, there is some value that can be assigned to the second variable so that the pair of variables does not violate any constraints between them.* Arc consistency is about ensuring that for every arc (relationship) between two nodes (variables), there is no inconsistency. 
   
3. **K-Consistency:** This generalizes the concept of consistency to sets of \( k \) variables. A CSP is \( k \)-consistent if, for any consistent assignment to \( k-1 \) nodes, there is a value that can be assigned to the \( k \)th node that does not cause any inconsistencies. Essentially, if you have a working solution for \( k-1 \) variables, you should be able to extend it to \( k \) variables without any problems. But k-consistency does not gurantee k-1, k-2, k-3, … consistency 
   
4. **Higher \( k \) More Expensive to Compute:** As the level of \( k \) increases, the computational cost to check consistency also increases. This is because the number of combinations of variables and the constraints to check grows exponentially with \( k \). 
   
5. **Strong \( k \)-Consistency:** This is a stronger form of \( k \)-consistency where a CSP is not just \( k \)-consistent but also all levels of consistency below \( k \). So, if a CSP is strongly \( k \)-consistent, it is also \( k-1 \), \( k-2 \), ..., and 1-consistent. 

6. **Claim: Strong \( n \)-Consistency Means We Can Solve Without Backtracking:** The claim here is that *if a CSP is strongly consistent up to the number of variables \( n \) (which means it's \( n \)-consistent and all levels below), you can solve the CSP without having to backtrack*. Backtracking is a search algorithm that tries to build a solution incrementally and backtracks as soon as it determines that a partial solution cannot possibly be completed to a valid solution. 
	1. Strong \( n \)-consistency allows for a systematic choice of values for each variable without backtracking because at each step, you're guaranteed to have a consistent assignment for the next variable based on the level of consistency achieved. 
	   
7. **Path Consistency**: The term "path consistency" mentioned in the image refers to 3- consistency. It ensures that for any two variables in the CSP, their relationship remains consistent when considered along with a third variable. Path consistency is a middleground between arc-consistency and n-consistency

# Cutset Conditioning
In graph theory, a **cutset** (also known as a **cut-set** or **vertex cut**) is a set of edges or vertices whose removal from a graph increases the number of connected components in the graph. Essentially, it's a way to "cut" the graph into two or more disconnected subgraphs.

### Types of Cutsets:

1. **Edge Cutset (or Edge Cut):**
   - A set of edges whose removal makes the graph disconnected or increases the number of connected components.
   - For example, in a connected graph, if removing a set of edges makes the graph disconnected, that set of edges is an edge cutset.

2. **Vertex Cutset (or Vertex Cut):**
   - A set of vertices whose removal makes the graph disconnected or increases the number of connected components.
   - If you remove a vertex (or a set of vertices) and the graph becomes disconnected, those vertices form a vertex cutset.

