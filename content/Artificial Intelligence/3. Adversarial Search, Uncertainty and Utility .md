Adversarial search is a type of search in artificial intelligence (AI) used to make optimal decisions in competitive environments, such as games, where multiple agents or players are competing against each other. This type of search assumes that one player’s gain is another player’s loss, which is common in zero-sum games like chess, checkers, and tic-tac-toe.

### 1. **Minimax Algorithm:**
The minimax algorithm is a fundamental method in adversarial search. It is used to determine the best move for a player assuming that the opponent is also playing optimally.
### 2. **Alpha-Beta Pruning:**
Alpha-beta pruning is an optimization technique for the minimax algorithm. It reduces the number of nodes that need to be evaluated in the search tree, making the algorithm more efficient.

- **How It Works:**
  - As the minimax algorithm explores the tree, it keeps track of two values:
    - **Alpha (α):** The best value that the maximizing player can guarantee so far.
    - **Beta (β):** The best value that the minimizing player can guarantee so far.
  - During the search, if the algorithm finds a move that leads to a value worse than the current alpha or beta, it can stop evaluating that branch further, because no matter what moves are made, that branch will not affect the final decision.
  - This process of cutting off unnecessary branches is called "pruning."

- **Benefits:**
  - Alpha-beta pruning significantly reduces the number of nodes evaluated, allowing deeper exploration of the game tree within the same computational resources.
  - In the best case, alpha-beta pruning can reduce the time complexity from \($O(b^d)$\) to \($O(b^{d/2}$)\), where \(b\) is the branching factor and \(d\) is the depth of the tree.

# Expectimax
Yes, pruning can be applied to Expectimax trees in AI, although it's more complex compared to Minimax trees due to the presence of chance nodes. Some techniques for pruning Expectimax trees include: 
1. **Alpha-beta pruning:** This method, similar to its use in Minimax trees, involves using alpha and beta bounds to eliminate branches that won't affect the final decision. While effective, the presence of chance nodes in Expectimax trees may reduce the efficiency of alpha-beta pruning. 
   
2. **Limited depth search:** Limiting the depth of the search tree can effectively control the branching factor, simplifying the decision process. 
   
3. **Pruning insignificant chance nodes:** When chance nodes lead to outcomes with very similar utility values, these nodes can sometimes be pruned, using the expected value of these outcomes instead, without significantly sacrificing accuracy. 
   
4. **Pruning with heuristics:** Using domain-specific heuristics, parts of the tree that are unlikely to contain optimal decisions can be identified and pruned. 

They carry the risk of overlooking significant outcomes. The choice of pruning strategy and its parameters should be made carefully, considering the specific requirements and constraints of the problem at hand.

### Zero-Sum Games
- **Definition**: In a zero-sum game, the total payoff among all players remains constant, meaning that any gain by one player comes at the exact expense of another player. The sum of all players' payoffs in the game equals zero.
- **Example**: Chess is a classic example. If one player wins, the other loses, and the total outcome is balanced (one player’s win is exactly equal to the other player’s loss).

### Non-Zero-Sum Games
- **Definition**: In a non-zero-sum game, the total payoff to all players does not necessarily sum to zero. The players' outcomes can be cooperative, competitive, or somewhere in between, leading to situations where both players can benefit (or lose) simultaneously.
- **Example**: In the context of AI, non-zero-sum games often model scenarios where collaboration can lead to better outcomes for all participants.
- **AI Application**: Non-zero-sum games are useful in AI for modeling scenarios that involve cooperation, such as in multi-agent systems where agents might work together to achieve a common goal. Techniques like **Nash equilibrium** and **Pareto efficiency** are often used to find optimal strategies in such games.

### MEU Principle in AI 
The MEU Principle stands for Maximum Expected Utility. An AI uses this principle to choose an action that maximizes its expected utility, given by: 

$\text{MEU(a)} = \sum_i P(S_i|a)U(S_i)$ 

where is the probability of state given action , and is the utility of state.

